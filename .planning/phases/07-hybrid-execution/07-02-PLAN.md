---
phase: 07-hybrid-execution
plan: 02
type: execute
depends_on: ["07-01"]
files_modified: [src/ggml/cpu_backend.rs, src/ggml/hip_backend/backend.rs, src/ggml/hybrid_scheduler.rs]
autonomous: true
---

<objective>
Implement per-operation CPU/GPU availability tracking in existing backends.

Purpose: Make CpuBackend and HipBackend implement the CapableBackend trait to declare their operation capabilities. This enables the HybridScheduler to query what each backend can execute and make informed scheduling decisions.
Output: CapableBackend implementations for CPU and GPU backends with capability declarations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
@~/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/07-hybrid-execution/07-01-PLAN.md
@.planning/phases/07-hybrid-execution/07-01-SUMMARY.md

@src/ggml/backend.rs
@src/ggml/cpu_backend.rs
@src/ggml/hip_backend/backend.rs
@src/ggml/op.rs
@src/ggml/hybrid_scheduler.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Map Op enum to OpType for capability tracking</name>
  <files>src/ggml/hybrid_scheduler.rs</files>
  <action>
    Add Op to OpType mapping function in hybrid_scheduler.rs:

    ```rust
    impl OpType {
        /// Map from Op to OpType for capability checking
        pub fn from_op(op: &Op) -> Option<Self> {
            match op {
                Op::MatMul { .. } => Some(OpType::MatMul),
                Op::QuantizedMatMul { .. } => Some(OpType::QuantizedMatMul),
                Op::Add { .. } => Some(OpType::Add),
                Op::Scale { .. } => Some(OpType::Scale),
                Op::Softmax { .. } => Some(OpType::Softmax),
                Op::Attention { .. } => Some(OpType::Attention),
                Op::Dequantize { .. } => Some(OpType::Dequantize),
                Op::Constant { .. } | Op::View { .. } | Op::Permute { .. } => None,
                // Metadata ops don't need backend selection
            }
        }
    }
    ```

    This bridges the existing Op enum with the capability system.
  </action>
  <verify>OpType::from_op mapping function added</verify>
  <done>Op to OpType mapping implemented</done>
</task>

<task type="auto">
  <name>Task 2: Implement CapableBackend for CpuBackend</name>
  <files>src/ggml/cpu_backend.rs</files>
  <action>
    Add CapableBackend implementation to src/ggml/cpu_backend.rs:

    First, import the trait:
    ```rust
    use crate::ggml::hybrid_scheduler::{CapableBackend, OpCapability, OpType, OpCost};
    ```

    Then implement the trait:
    ```rust
    impl CapableBackend for CpuBackend {
        fn capabilities(&self) -> std::collections::HashSet<OpCapability> {
            use crate::ggml::DType;
            let mut caps = std::collections::HashSet::new();

            // CPU supports all basic operations for all data types
            for dtype in [DType::F32, DType::F16, DType::I32, DType::I8] {
                caps.insert(OpCapability {
                    op_type: OpType::MatMul,
                    supported_dtypes: vec![dtype],
                    max_tensor_size: None, // CPU limited by RAM only
                    requires_feature: None,
                });
                caps.insert(OpCapability {
                    op_type: OpType::Add,
                    supported_dtypes: vec![dtype],
                    max_tensor_size: None,
                    requires_feature: None,
                });
                caps.insert(OpCapability {
                    op_type: OpType::Scale,
                    supported_dtypes: vec![dtype],
                    max_tensor_size: None,
                    requires_feature: None,
                });
                caps.insert(OpCapability {
                    op_type: OpType::Softmax,
                    supported_dtypes: vec![DType::F32],
                    max_tensor_size: None,
                    requires_feature: None,
                });
            }

            // Quantized operations (CPU dequantization always available)
            caps.insert(OpCapability {
                op_type: OpType::QuantizedMatMul,
                supported_dtypes: vec![DType::F32],
                max_tensor_size: None,
                requires_feature: None,
            });

            caps.insert(OpCapability {
                op_type: OpType::Dequantize,
                supported_dtypes: vec![DType::F32],
                max_tensor_size: None,
                requires_feature: None,
            });

            caps
        }

        fn op_capability(&self, op: &Op) -> Option<OpCapability> {
            use crate::ggml::DType;
            let op_type = OpType::from_op(op)?;

            Some(OpCapability {
                op_type,
                supported_dtypes: vec![DType::F32], // CPU supports F32 for all ops
                max_tensor_size: None,
                requires_feature: None,
            })
        }
    }
    ```

    This declares that CPU can execute all operations with various data types.
  </action>
  <verify>CapableBackend implemented for CpuBackend</verify>
  <done>CPU capability tracking implemented</done>
</task>

<task type="auto">
  <name>Task 3: Implement CapableBackend for HipBackend</name>
  <files>src/ggml/hip_backend/backend.rs</files>
  <action>
    Add CapableBackend implementation to src/ggml/hip_backend/backend.rs:

    First, import at top of file:
    ```rust
    #[cfg(feature = "rocm")]
    use crate::ggml::hybrid_scheduler::{CapableBackend, OpCapability, OpType, OpCost};
    ```

    Then implement the trait (feature-gated):
    ```rust
    #[cfg(feature = "rocm")]
    impl CapableBackend for HipBackend {
        fn capabilities(&self) -> std::collections::HashSet<OpCapability> {
            use crate::ggml::DType;
            let mut caps = std::collections::HashSet::new();

            // GPU supports MatMul, Add, Scale, Softmax for F32
            let gpu_dtypes = vec![DType::F32, DType::F16];
            for dtype in gpu_dtypes {
                caps.insert(OpCapability {
                    op_type: OpType::MatMul,
                    supported_dtypes: vec![dtype],
                    max_tensor_size: Some(512 * 1024 * 1024), // 512M element limit
                    requires_feature: Some("rocm".to_string()),
                });
                caps.insert(OpCapability {
                    op_type: OpType::Add,
                    supported_dtypes: vec![dtype],
                    max_tensor_size: Some(512 * 1024 * 1024),
                    requires_feature: Some("rocm".to_string()),
                });
                caps.insert(OpCapability {
                    op_type: OpType::Scale,
                    supported_dtypes: vec![dtype],
                    max_tensor_size: Some(512 * 1024 * 1024),
                    requires_feature: Some("rocm".to_string()),
                });
            }

            // Softmax only F32
            caps.insert(OpCapability {
                op_type: OpType::Softmax,
                supported_dtypes: vec![DType::F32],
                max_tensor_size: Some(512 * 1024 * 1024),
                requires_feature: Some("rocm".to_string()),
            });

            // Quantized operations - depends on available kernels
            caps.insert(OpCapability {
                op_type: OpType::QuantizedMatMul,
                supported_dtypes: vec![DType::F32],
                max_tensor_size: Some(512 * 1024 * 1024),
                requires_feature: Some("rocm".to_string()),
            });

            caps.insert(OpCapability {
                op_type: OpType::Dequantize,
                supported_dtypes: vec![DType::F32],
                max_tensor_size: Some(512 * 1024 * 1024),
                requires_feature: Some("rocm".to_string()),
            });

            // Attention operations - check if flash attention is available
            // For now, declare basic attention support
            caps.insert(OpCapability {
                op_type: OpType::Attention,
                supported_dtypes: vec![DType::F32],
                max_tensor_size: Some(128 * 1024 * 128), // Smaller for attention
                requires_feature: Some("rocm".to_string()),
            });

            caps
        }

        fn op_capability(&self, op: &Op) -> Option<OpCapability> {
            use crate::ggml::DType;
            let op_type = OpType::from_op(op)?;

            let (dtypes, max_size) = match op_type {
                OpType::MatMul | OpType::Add | OpType::Scale => (vec![DType::F32, DType::F16], 512 * 1024 * 1024),
                OpType::Softmax | OpType::QuantizedMatMul | OpType::Dequantize => (vec![DType::F32], 512 * 1024 * 1024),
                OpType::Attention => (vec![DType::F32], 128 * 1024 * 128),
            };

            Some(OpCapability {
                op_type,
                supported_dtypes: dtypes,
                max_tensor_size: Some(max_size),
                requires_feature: Some("rocm".to_string()),
            })
        }
    }
    ```

    This declares GPU capabilities with appropriate limits and feature requirements.
  </action>
  <verify>CapableBackend implemented for HipBackend</verify>
  <done>GPU capability tracking implemented</done>
</task>

<task type="auto">
  <name>Task 4: Add tests for capability queries</name>
  <files>src/ggml/cpu_backend.rs</files>
  <action>
    Add capability tests to cpu_backend.rs:

    ```rust
    #[cfg(test)]
    mod capability_tests {
        use super::*;
        use crate::ggml::hybrid_scheduler::{CapableBackend, OpType};

        #[test]
        fn test_cpu_capabilities_includes_matmul() {
            let backend = CpuBackend::new();
            let caps = backend.capabilities();
            assert!(caps.iter().any(|c| c.op_type == OpType::MatMul));
        }

        #[test]
        fn test_cpu_can_execute_matmul() {
            let backend = CpuBackend::new();
            let op = Op::MatMul {
                a: crate::ggml::TensorId::new(0),
                b: crate::ggml::TensorId::new(1),
            };
            assert!(backend.can_execute(&op));
        }

        #[test]
        fn test_cpu_can_execute_softmax() {
            let backend = CpuBackend::new();
            let op = Op::Softmax {
                input: crate::ggml::TensorId::new(0),
            };
            assert!(backend.can_execute(&op));
        }

        #[test]
        fn test_cpu_supports_all_basic_ops() {
            let backend = CpuBackend::new();
            let caps = backend.capabilities();

            let mut found_matmul = false;
            let mut found_add = false;
            let mut found_scale = false;
            let mut found_softmax = false;

            for cap in &caps {
                match cap.op_type {
                    OpType::MatMul => found_matmul = true,
                    OpType::Add => found_add = true,
                    OpType::Scale => found_scale = true,
                    OpType::Softmax => found_softmax = true,
                    _ => {}
                }
            }

            assert!(found_matmul, "CPU should support MatMul");
            assert!(found_add, "CPU should support Add");
            assert!(found_scale, "CPU should support Scale");
            assert!(found_softmax, "CPU should support Softmax");
        }
    }
    ```

    Also add similar tests to hip_backend/backend.rs (feature-gated).
  </action>
  <verify>Capability tests added and passing</verify>
  <done>Tests validate capability declarations</done>
</task>

</tasks>

<verification>
- [ ] OpType::from_op mapping function implemented
- [ ] CpuBackend implements CapableBackend
- [ ] HipBackend implements CapableBackend (feature-gated)
- [ ] Capability tests added and passing
- [ ] cargo check passes
</verification>

<success_criteria>
- Both CPU and GPU backends declare their operation capabilities
- Scheduler can query backend capabilities
- Tests verify capability declarations are accurate
- Feature gating ensures GPU code only compiles with rocm feature
</success_criteria>

<output>
After completion, create `.planning/phases/07-hybrid-execution/07-02-SUMMARY.md`
</output>
