---
phase: 07-hybrid-execution
plan: 04
type: execute
depends_on: ["07-01", "07-02", "07-03"]
files_modified: [src/ggml/hybrid_scheduler.rs, tests/hybrid_scheduler_tests.rs]
autonomous: true
---

<objective>
Add telemetry for execution path debugging and performance monitoring.

Purpose: Enable tracking of which backend executes each operation, execution times, and selection reasons. This telemetry helps debug scheduler decisions and identify optimization opportunities.
Output: Telemetry system with execution event tracking, statistics, and debug output.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
@~/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@planning/STATE.md

@.planning/phases/07-hybrid-execution/07-01-SUMMARY.md
@.planning/phases/07-hybrid-execution/07-02-SUMMARY.md
@.planning/phases/07-hybrid-execution/07-03-SUMMARY.md

@src/ggml/hybrid_scheduler.rs
@src/ggml/executor.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add execution timing to HybridExecutor</name>
  <files>src/ggml/hybrid_scheduler.rs</files>
  <action>
    Enhance HybridExecutor to record execution times:

    ```rust
    use std::time::Instant;

    impl HybridExecutor {
        fn execute_op_with_telemetry(
            &mut self,
            op: &Op,
            inputs: &[TensorId],
            outputs: &[TensorId],
        ) -> GgmlResult<()> {
            let start = Instant::now();
            let op_type = OpType::from_op(op);

            // Select and execute
            let backend_name = self.select_backend_for_op(op)?;
            let backend = self.get_backend(&backend_name)?;

            let result = backend.execute_op(op, inputs, outputs);
            let duration = start.elapsed();

            // Record telemetry
            if let Some(op_type) = op_type {
                let event = ExecutionEvent {
                    timestamp: Instant::now(),
                    operation: op_type,
                    backend: backend_name.clone(),
                    reason: SelectionReason::CpuFallback,  // Simplified for now
                    actual_duration_us: Some(duration.as_micros() as u64),
                };
                self.scheduler_mut().record_execution(event);
            }

            result
        }
    }

    impl GgmlBackend for HybridExecutor {
        fn execute_op(
            &mut self,
            op: &Op,
            inputs: &[TensorId],
            outputs: &[TensorId],
        ) -> GgmlResult<()> {
            self.execute_op_with_telemetry(op, inputs, outputs)
        }
    }
    ```

    Now each operation execution is timed and recorded.
  </action>
  <verify>Execution timing added to HybridExecutor</verify>
  <done>Telemetry records actual execution times</done>
</task>

<task type="auto">
  <name>Task 2: Add telemetry reporting methods</name>
  <files>src/ggml/hybrid_scheduler.rs</files>
  <action>
    Add comprehensive reporting methods:

    ```rust
    use std::collections::HashMap;

    impl HybridScheduler {
        /// Get execution summary by backend
        pub fn execution_summary(&self) -> BackendExecutionSummary {
            let mut by_backend: HashMap<String, Vec<&ExecutionEvent>> = HashMap::new();
            let mut total_time_us: u64 = 0;

            for event in &self.telemetry {
                by_backend
                    .entry(event.backend.clone())
                    .or_insert_with(Vec::new)
                    .push(event);

                if let Some(duration) = event.actual_duration_us {
                    total_time_us += duration;
                }
            }

            let mut gpu_time = 0;
            let mut cpu_time = 0;
            let mut gpu_ops = 0;
            let mut cpu_ops = 0;

            for (backend, events) in &by_backend {
                let backend_time: u64 = events.iter()
                    .filter_map(|e| e.actual_duration_us)
                    .sum();

                match backend.as_str() {
                    "gpu" => {
                        gpu_time = backend_time;
                        gpu_ops = events.len();
                    }
                    "cpu" => {
                        cpu_time = backend_time;
                        cpu_ops = events.len();
                    }
                    _ => {}
                }
            }

            BackendExecutionSummary {
                total_operations: self.telemetry.len(),
                gpu_operations: gpu_ops,
                cpu_operations: cpu_ops,
                total_time_us,
                gpu_time_us: gpu_time,
                cpu_time_us: cpu_time,
            }
        }

        /// Print a debug summary of execution
        pub fn print_debug_summary(&self) {
            let summary = self.execution_summary();

            eprintln!("=== Hybrid Scheduler Execution Summary ===");
            eprintln!("Total operations: {}", summary.total_operations);
            eprintln!("GPU operations: {} ({:.1}%)",
                summary.gpu_operations,
                (summary.gpu_operations as f64 / summary.total_operations as f64) * 100.0
            );
            eprintln!("CPU operations: {} ({:.1}%)",
                summary.cpu_operations,
                (summary.cpu_operations as f64 / summary.total_operations as f64) * 100.0
            );
            eprintln!("Total time: {} us", summary.total_time_us);
            eprintln!("GPU time: {} us ({:.1}%)",
                summary.gpu_time_us,
                (summary.gpu_time_us as f64 / summary.total_time_us as f64) * 100.0
            );
            eprintln!("CPU time: {} us ({:.1}%)",
                summary.cpu_time_us,
                (summary.cpu_time_us as f64 / summary.total_time_us as f64) * 100.0
            );
            eprintln!("=========================================");
        }

        /// Get operations by type
        pub fn operations_by_type(&self, op_type: OpType) -> Vec<&ExecutionEvent> {
            self.telemetry.iter()
                .filter(|e| e.operation == op_type)
                .collect()
        }
    }

    #[derive(Debug, Clone)]
    pub struct BackendExecutionSummary {
        pub total_operations: usize,
        pub gpu_operations: usize,
        pub cpu_operations: usize,
        pub total_time_us: u64,
        pub gpu_time_us: u64,
        pub cpu_time_us: u64,
    }
    ```

    These methods provide visibility into scheduler decisions.
  </action>
  <verify>Telemetry reporting methods added</verify>
  <done>Debug summary and statistics available</done>
</task>

<task type="auto">
  <name>Task 3: Create integration test file</name>
  <files>tests/hybrid_scheduler_tests.rs</files>
<action>
    Create tests/hybrid_scheduler_tests.rs:

    ```rust
    //! Integration tests for hybrid execution scheduler

    use rocmforge::ggml::hybrid_scheduler::{
        HybridScheduler, ExecutionStrategy, SelectionReason, OpCost,
        ExecutionEvent, BackendStats,
    };
    use rocmforge::ggml::{Op, TensorId};
    use std::time::Instant;

    #[test]
    fn test_scheduler_creation() {
        let scheduler = HybridScheduler::new(ExecutionStrategy::Automatic);
        let stats = scheduler.backend_usage_stats();
        assert_eq!(stats.total_operations, 0);
    }

    #[test]
    fn test_telemetry_recording() {
        let mut scheduler = HybridScheduler::new(ExecutionStrategy::GpuPreferred);

        let event = ExecutionEvent {
            timestamp: Instant::now(),
            operation: rocmforge::ggml::hybrid_scheduler::OpType::MatMul,
            backend: "cpu".to_string(),
            reason: SelectionReason::CpuFallback,
            actual_duration_us: Some(100),
        };

        scheduler.record_execution(event);

        let telemetry = scheduler.get_telemetry();
        assert_eq!(telemetry.len(), 1);
        assert_eq!(telemetry[0].backend, "cpu");
    }

    #[test]
    fn test_clear_telemetry() {
        let mut scheduler = HybridScheduler::new(ExecutionStrategy::CpuPreferred);

        let event = ExecutionEvent {
            timestamp: Instant::now(),
            operation: rocmforge::ggml::hybrid_scheduler::OpType::MatMul,
            backend: "cpu".to_string(),
            reason: SelectionReason::CpuFallback,
            actual_duration_us: Some(100),
        };

        scheduler.record_execution(event);
        assert_eq!(scheduler.get_telemetry().len(), 1);

        scheduler.clear_telemetry();
        assert_eq!(scheduler.get_telemetry().len(), 0);
    }

    #[test]
    fn test_backend_stats() {
        let mut scheduler = HybridScheduler::new(ExecutionStrategy::Automatic);

        // Record some events
        for i in 0..3 {
            scheduler.record_execution(ExecutionEvent {
                timestamp: Instant::now(),
                operation: rocmforge::ggml::hybrid_scheduler::OpType::MatMul,
                backend: "gpu".to_string(),
                reason: SelectionReason::GpuAvailable,
                actual_duration_us: Some(100 + i * 10),
            });
        }

        for i in 0..2 {
            scheduler.record_execution(ExecutionEvent {
                timestamp: Instant::now(),
                operation: rocmforge::ggml::hybrid_scheduler::OpType::Softmax,
                backend: "cpu".to_string(),
                reason: SelectionReason::CpuFallback,
                actual_duration_us: Some(50),
            });
        }

        let stats = scheduler.backend_usage_stats();
        assert_eq!(stats.total_operations, 5);
        assert_eq!(stats.gpu_operations, 3);
        assert_eq!(stats.cpu_operations, 2);
    }

    #[test]
    fn test_execution_summary() {
        let mut scheduler = HybridScheduler::new(ExecutionStrategy::Automatic);

        // Add some test events
        scheduler.record_execution(ExecutionEvent {
            timestamp: Instant::now(),
            operation: rocmforge::ggml::hybrid_scheduler::OpType::MatMul,
            backend: "gpu".to_string(),
            reason: SelectionReason::GpuAvailable,
            actual_duration_us: Some(100),
        });

        scheduler.record_execution(ExecutionEvent {
            timestamp: Instant::now(),
            operation: rocmforge::ggml::hybrid_scheduler::OpType::Softmax,
            backend: "cpu".to_string(),
            reason: SelectionReason::CpuFallback,
            actual_duration_us: Some(50),
        });

        let summary = scheduler.execution_summary();
        assert_eq!(summary.total_operations, 2);
        assert_eq!(summary.gpu_operations, 1);
        assert_eq!(summary.cpu_operations, 1);
        assert_eq!(summary.total_time_us, 150);
        assert_eq!(summary.gpu_time_us, 100);
        assert_eq!(summary.cpu_time_us, 50);
    }

    #[test]
    fn test_print_debug_summary() {
        let mut scheduler = HybridScheduler::new(ExecutionStrategy::Automatic);

        scheduler.record_execution(ExecutionEvent {
            timestamp: Instant::now(),
            operation: rocmforge::ggml::hybrid_scheduler::OpType::MatMul,
            backend: "gpu".to_string(),
            reason: SelectionReason::GpuAvailable,
            actual_duration_us: Some(1000),
        });

        // Should not panic
        scheduler.print_debug_summary();
    }
    ```

    Add to tests/mod.rs or create a new test module as needed.
  </action>
  <verify>Integration test file created</verify>
  <done>Tests validate telemetry functionality</done>
</task>

<task type="auto">
  <name>Task 4: Export telemetry types and add documentation</name>
  <files>src/ggml/mod.rs</files>
<action>
    Update exports in src/ggml/mod.rs:

    ```rust
    pub use hybrid_scheduler::{
        CapableBackend, HybridScheduler, HybridExecutor, ExecutionStrategy,
        OpCapability, OpType, OpCost, BackendSelection, SelectionReason,
        ExecutionEvent, BackendStats, BackendExecutionSummary,
    };
    ```

    Add documentation comment to hybrid_scheduler.rs:

    ```rust
    //! # Hybrid Execution Scheduler
    //!
    //! This module provides automatic CPU/GPU operation selection for maximum
    //! compatibility and performance.
    //!
    //! ## Usage
    //!
    //! ```rust
    //! use rocmforge::ggml::{HybridScheduler, ExecutionStrategy};
    //!
    //! // Create a scheduler that automatically selects the best backend
    //! let scheduler = HybridScheduler::new(ExecutionStrategy::Automatic);
    //!
    //! // Or prefer GPU with CPU fallback
    //! let scheduler = HybridScheduler::new(ExecutionStrategy::GpuPreferred);
    //! ```
    //!
    //! ## Telemetry
    //!
    //! The scheduler tracks execution decisions and performance:
    //!
    //! ```rust
    //! let summary = scheduler.execution_summary();
    //! println!("GPU: {} us, CPU: {} us", summary.gpu_time_us, summary.cpu_time_us);
    //! ```
    ```

    Also add a README in tests/hybrid_scheduler_tests.rs header:
    ```rust
    //! Hybrid Scheduler Integration Tests
    //!
    //! Tests for the hybrid execution scheduler covering:
    //! - Backend selection logic
    //! - Telemetry recording and reporting
    //! - Cost model accuracy
    //! - Error handling
    //!
    //! Run with: cargo test hybrid_scheduler
    ```
  </action>
  <verify>Types exported and documented</verify>
  <done>Documentation complete</done>
</task>

</tasks>

<verification>
- [ ] Execution timing recorded in HybridExecutor
- [ ] Telemetry reporting methods (summary, debug print) implemented
- [ ] Integration tests created in tests/hybrid_scheduler_tests.rs
- [ ] Telemetry types exported from mod.rs
- [ ] Documentation comments added
- [ ] All tests passing
</verification>

<success_criteria>
- Telemetry tracks which backend executed each operation
- Execution times are recorded for performance analysis
- Debug summary shows GPU/CPU usage breakdown
- Tests validate telemetry recording and reporting
- Documentation explains how to use telemetry
</success_criteria>

<output>
After completion, create `.planning/phases/07-hybrid-execution/07-04-SUMMARY.md`
</output>
